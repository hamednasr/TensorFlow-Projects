{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNetV2 transfer learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPq9pIwwqy678gMJeNfsNLN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamednasr/TensorFlow-Projects/blob/main/MobileNetV2_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MobileNetv2 feature extraction transfer learning"
      ],
      "metadata": {
        "id": "hJwOLF0H9Wt2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **mission** :we want to classify the images of ten different foods, using the MobileNetv2 and transfer learning, using only 10% of the training data which is only 75 photos in each class, the test set contains 250 images in each class. "
      ],
      "metadata": {
        "id": "VYjPb5x7_6Uh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LGfbwCxm8nl3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import datetime\n",
        "from tensorflow.keras import layers, optimizers\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##load data:"
      ],
      "metadata": {
        "id": "yRTLB_q8_2hI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExBwyZ4I_Uto",
        "outputId": "d18894d0-999a-440d-e310-6846b484b1b2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-28 08:14:51--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.74.128, 209.85.145.128, 209.85.146.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.74.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   208MB/s    in 0.8s    \n",
            "\n",
            "2022-02-28 08:14:52 (208 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile('10_food_classes_10_percent.zip')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "0O0sU0oO_Wan"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dirpath, dirnames,filenames in os.walk('10_food_classes_10_percent'):\n",
        "  print(f'there are {len(dirnames)} folders and {len(filenames)} images in {dirpath}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTnHjBLA_WYX",
        "outputId": "f3cb885e-6647-4465-bfc5-cc03e896d4a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there are 2 folders and 0 images in 10_food_classes_10_percent\n",
            "there are 10 folders and 0 images in 10_food_classes_10_percent/test\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/fried_rice\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/chicken_wings\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/pizza\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/steak\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/grilled_salmon\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/sushi\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/chicken_curry\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/ramen\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/hamburger\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/ice_cream\n",
            "there are 10 folders and 0 images in 10_food_classes_10_percent/train\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/fried_rice\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/chicken_wings\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/pizza\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/steak\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/grilled_salmon\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/sushi\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/chicken_curry\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/ramen\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/hamburger\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/ice_cream\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess data:"
      ],
      "metadata": {
        "id": "S8ozWNXoBnRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255)"
      ],
      "metadata": {
        "id": "xCEHixpz_zB4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '10_food_classes_10_percent/train'\n",
        "test_dir = '10_food_classes_10_percent/test'"
      ],
      "metadata": {
        "id": "NFtrfPSKEgbU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_datagen.flow_from_directory(train_dir,target_size=(224,224))\n",
        "test_data = test_datagen.flow_from_directory(test_dir,target_size=(224,224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-4bOXNd_z3y",
        "outputId": "39e36c0d-02c3-4803-e529-460adc67fc8a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 images belonging to 10 classes.\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## building model "
      ],
      "metadata": {
        "id": "wYA1SkGAFUMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MobileNetv2 = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5'\n",
        "feature_Extractor_layers = hub.KerasLayer(MobileNetv2,name='MobileNetv2',\n",
        "                                          trainable=False,input_shape= (224,224,3))"
      ],
      "metadata": {
        "id": "kdesMMWQFylU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MobileNetmodel = tf.keras.Sequential([\n",
        "                             \n",
        "              feature_Extractor_layers,\n",
        "\n",
        "              # layers.Dense(128,activation='relu'),\n",
        "              layers.Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "MobileNetmodel.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "                       optimizer = tf.keras.optimizers.Adam(),\n",
        "                       metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "r63qBdvo_z1G"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MobileNetmodel.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBoGm68Q_y-M",
        "outputId": "52eee070-d49f-4d78-f724-c2f3a2c89ed0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " MobileNetv2 (KerasLayer)    (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,270,794\n",
            "Trainable params: 12,810\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creat tensorboard callbacks:"
      ],
      "metadata": {
        "id": "V2eeAjZTW_X9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + '/' + experiment_name + '/' +datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,write_images=True)\n",
        "  print(f'saving tensorboard log files to: {log_dir}')\n",
        "  return tensorboard_callback\n"
      ],
      "metadata": {
        "id": "NpmqXRbzXC9S"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fit the model with 10% of the training data:"
      ],
      "metadata": {
        "id": "NQ6Q98D3ZBz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MobileNetmodel.fit(train_data, epochs=15,\n",
        "                   validation_data = test_data, \n",
        "                   callbacks=create_tensorboard_callback('tensorboard', 'MobileNetv2'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-LMzSCN_y6n",
        "outputId": "64067bb6-c550-42c6-b6d5-6dbe2c0457c1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving tensorboard log files to: tensorboard/MobileNetv2/220228-082950\n",
            "Epoch 1/15\n",
            "24/24 [==============================] - 21s 838ms/step - loss: 1.8970 - accuracy: 0.3573 - val_loss: 1.2645 - val_accuracy: 0.6180\n",
            "Epoch 2/15\n",
            "24/24 [==============================] - 19s 806ms/step - loss: 1.0149 - accuracy: 0.7107 - val_loss: 0.8709 - val_accuracy: 0.7396\n",
            "Epoch 3/15\n",
            "24/24 [==============================] - 19s 804ms/step - loss: 0.7165 - accuracy: 0.8147 - val_loss: 0.7477 - val_accuracy: 0.7720\n",
            "Epoch 4/15\n",
            "24/24 [==============================] - 19s 797ms/step - loss: 0.5567 - accuracy: 0.8653 - val_loss: 0.6754 - val_accuracy: 0.7904\n",
            "Epoch 5/15\n",
            "24/24 [==============================] - 18s 790ms/step - loss: 0.4640 - accuracy: 0.9027 - val_loss: 0.6417 - val_accuracy: 0.8020\n",
            "Epoch 6/15\n",
            "24/24 [==============================] - 25s 1s/step - loss: 0.3928 - accuracy: 0.9173 - val_loss: 0.6126 - val_accuracy: 0.8096\n",
            "Epoch 7/15\n",
            "24/24 [==============================] - 18s 784ms/step - loss: 0.3342 - accuracy: 0.9360 - val_loss: 0.5971 - val_accuracy: 0.8108\n",
            "Epoch 8/15\n",
            "24/24 [==============================] - 18s 786ms/step - loss: 0.2925 - accuracy: 0.9507 - val_loss: 0.5837 - val_accuracy: 0.8096\n",
            "Epoch 9/15\n",
            "24/24 [==============================] - 18s 773ms/step - loss: 0.2535 - accuracy: 0.9707 - val_loss: 0.5728 - val_accuracy: 0.8168\n",
            "Epoch 10/15\n",
            "24/24 [==============================] - 25s 1s/step - loss: 0.2246 - accuracy: 0.9707 - val_loss: 0.5613 - val_accuracy: 0.8208\n",
            "Epoch 11/15\n",
            "24/24 [==============================] - 18s 792ms/step - loss: 0.1997 - accuracy: 0.9827 - val_loss: 0.5575 - val_accuracy: 0.8192\n",
            "Epoch 12/15\n",
            "24/24 [==============================] - 18s 788ms/step - loss: 0.1770 - accuracy: 0.9840 - val_loss: 0.5514 - val_accuracy: 0.8208\n",
            "Epoch 13/15\n",
            "24/24 [==============================] - 18s 772ms/step - loss: 0.1579 - accuracy: 0.9880 - val_loss: 0.5542 - val_accuracy: 0.8196\n",
            "Epoch 14/15\n",
            "24/24 [==============================] - 18s 766ms/step - loss: 0.1429 - accuracy: 0.9920 - val_loss: 0.5472 - val_accuracy: 0.8212\n",
            "Epoch 15/15\n",
            "24/24 [==============================] - 18s 790ms/step - loss: 0.1292 - accuracy: 0.9973 - val_loss: 0.5409 - val_accuracy: 0.8256\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff566dc05d0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MobileNetmodel.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7W7HLI2_y3w",
        "outputId": "cf1575a6-99b2-45a0-dc12-5d802e6176f5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 15s 183ms/step - loss: 0.5409 - accuracy: 0.8256\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5409265756607056, 0.8256000280380249]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(MobileNetmodel.predict(test_data),axis=1)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMizrSxAZzkC",
        "outputId": "0ee6ebf5-4320-423c-ebad-6dff6ab86c16"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 9, 5, ..., 9, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## upload data to tensorboard:\n"
      ],
      "metadata": {
        "id": "fyKXbhPFb1-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard dev upload --logdir ./tensorboard/ \\\n",
        "--name 'MobileNetv2 results on food data' \\\n",
        "--one_shot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xdCIXLvbKeh",
        "outputId": "9c022d7e-7351-4b75-d31d-14922b112cc0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/AUNsYb2eRv2kD78QQmPCdA/\n",
            "\n",
            "\u001b[1m[2022-02-28T08:35:15]\u001b[0m Started scanning logdir.\n",
            "\u001b[1m[2022-02-28T08:35:18]\u001b[0m Total uploaded: 128 scalars, 0 tensors, 3 binary objects (4.6 MB)\n",
            "\u001b[1m[2022-02-28T08:35:18]\u001b[0m Done scanning logdir.\n",
            "\n",
            "\n",
            "Done. View your TensorBoard at https://tensorboard.dev/experiment/AUNsYb2eRv2kD78QQmPCdA/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard dev list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN7-KdlScPUB",
        "outputId": "9823baf0-dd05-4bf4-d7c7-897280763727"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://tensorboard.dev/experiment/AUNsYb2eRv2kD78QQmPCdA/\n",
            "\tName                 MobileNetv2 results on food data\n",
            "\tDescription          [No Description]\n",
            "\tId                   AUNsYb2eRv2kD78QQmPCdA\n",
            "\tCreated              2022-02-28 08:35:15 (14 seconds ago)\n",
            "\tUpdated              2022-02-28 08:35:18 (11 seconds ago)\n",
            "\tRuns                 5\n",
            "\tTags                 5\n",
            "\tScalars              128\n",
            "\tTensor bytes         0\n",
            "\tBinary object bytes  4864363\n",
            "https://tensorboard.dev/experiment/umJfYK9XQjaQF6VKBQG3rw/\n",
            "\tName                 MobileNetv2 results on food data\n",
            "\tDescription          [No Description]\n",
            "\tId                   umJfYK9XQjaQF6VKBQG3rw\n",
            "\tCreated              2022-02-28 08:26:04 (9 minutes ago)\n",
            "\tUpdated              2022-02-28 08:26:04 (9 minutes ago)\n",
            "\tRuns                 1\n",
            "\tTags                 3\n",
            "\tScalars              20\n",
            "\tTensor bytes         0\n",
            "\tBinary object bytes  1620613\n",
            "https://tensorboard.dev/experiment/YQvKfa5ZS66UqBWy8nMHgQ/\n",
            "\tName                 efffient net vs. resnet\n",
            "\tDescription          comparing two different tensorflow hub feature extraction model architechture\n",
            "\tId                   YQvKfa5ZS66UqBWy8nMHgQ\n",
            "\tCreated              2022-02-27 18:53:57 (13 hours ago)\n",
            "\tUpdated              2022-02-27 18:53:59 (13 hours ago)\n",
            "\tRuns                 2\n",
            "\tTags                 3\n",
            "\tScalars              80\n",
            "\tTensor bytes         0\n",
            "\tBinary object bytes  6050481\n",
            "Total: 3 experiment(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GApAtKhuctcu"
      },
      "execution_count": 43,
      "outputs": []
    }
  ]
}