{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNetV2 transfer learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNR/nLlqQ2IMMGZRrq/209s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamednasr/TensorFlow-Projects/blob/main/MobileNetV2_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MobileNetv2 feature extraction transfer learning"
      ],
      "metadata": {
        "id": "hJwOLF0H9Wt2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **mission** :we want to classify the images of ten different foods, using the MobileNetv2 and transfer learning, using only 10% of the training data which is only 75 photos in each class, the test set contains 250 images in each class. "
      ],
      "metadata": {
        "id": "VYjPb5x7_6Uh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LGfbwCxm8nl3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import datetime\n",
        "from tensorflow.keras import layers, optimizers\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##load data:"
      ],
      "metadata": {
        "id": "yRTLB_q8_2hI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExBwyZ4I_Uto",
        "outputId": "d18894d0-999a-440d-e310-6846b484b1b2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-28 08:14:51--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.74.128, 209.85.145.128, 209.85.146.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.74.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   208MB/s    in 0.8s    \n",
            "\n",
            "2022-02-28 08:14:52 (208 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile('10_food_classes_10_percent.zip')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "0O0sU0oO_Wan"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dirpath, dirnames,filenames in os.walk('10_food_classes_10_percent'):\n",
        "  print(f'there are {len(dirnames)} folders and {len(filenames)} images in {dirpath}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTnHjBLA_WYX",
        "outputId": "f3cb885e-6647-4465-bfc5-cc03e896d4a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there are 2 folders and 0 images in 10_food_classes_10_percent\n",
            "there are 10 folders and 0 images in 10_food_classes_10_percent/test\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/fried_rice\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/chicken_wings\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/pizza\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/steak\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/grilled_salmon\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/sushi\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/chicken_curry\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/ramen\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/hamburger\n",
            "there are 0 folders and 250 images in 10_food_classes_10_percent/test/ice_cream\n",
            "there are 10 folders and 0 images in 10_food_classes_10_percent/train\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/fried_rice\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/chicken_wings\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/pizza\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/steak\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/grilled_salmon\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/sushi\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/chicken_curry\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/ramen\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/hamburger\n",
            "there are 0 folders and 75 images in 10_food_classes_10_percent/train/ice_cream\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess data:"
      ],
      "metadata": {
        "id": "S8ozWNXoBnRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255)"
      ],
      "metadata": {
        "id": "xCEHixpz_zB4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '10_food_classes_10_percent/train'\n",
        "test_dir = '10_food_classes_10_percent/test'"
      ],
      "metadata": {
        "id": "NFtrfPSKEgbU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_datagen.flow_from_directory(train_dir,target_size=(224,224))\n",
        "test_data = test_datagen.flow_from_directory(test_dir,target_size=(224,224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-4bOXNd_z3y",
        "outputId": "39e36c0d-02c3-4803-e529-460adc67fc8a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 images belonging to 10 classes.\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## building model "
      ],
      "metadata": {
        "id": "wYA1SkGAFUMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MobileNetv2 = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5'\n",
        "feature_Extractor_layers = hub.KerasLayer(MobileNetv2,name='MobileNetv2',\n",
        "                                          trainable=False,input_shape= (224,224,3))"
      ],
      "metadata": {
        "id": "kdesMMWQFylU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MobileNetmodel = tf.keras.Sequential([\n",
        "                             \n",
        "              feature_Extractor_layers,\n",
        "\n",
        "              # layers.Dense(128,activation='relu'),\n",
        "              layers.Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "MobileNetmodel.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "                       optimizer = tf.keras.optimizers.Adam(),\n",
        "                       metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "r63qBdvo_z1G"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MobileNetmodel.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBoGm68Q_y-M",
        "outputId": "f7c67578-ee7b-4479-b4c4-2299f7f4671b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " MobileNetv2 (KerasLayer)    (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,270,794\n",
            "Trainable params: 12,810\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creat tensorboard callbacks:"
      ],
      "metadata": {
        "id": "V2eeAjZTW_X9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + '/' + experiment_name + '/' +datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,write_images=True)\n",
        "  print(f'saving tensorboard log files to: {log_dir}')\n",
        "  return tensorboard_callback\n"
      ],
      "metadata": {
        "id": "NpmqXRbzXC9S"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fit the model with 10% of the training data:"
      ],
      "metadata": {
        "id": "NQ6Q98D3ZBz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MobileNetmodel.fit(train_data, epochs=10, \n",
        "                   callbacks=create_tensorboard_callback('tensorboard', 'MobileNetv2'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-LMzSCN_y6n",
        "outputId": "7d98d0e8-30ed-4685-8314-2d6874c80bc6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving tensorboard log files to: tensorboard/MobileNetv2/220228-081502\n",
            "Epoch 1/10\n",
            "24/24 [==============================] - 18s 186ms/step - loss: 2.0499 - accuracy: 0.2773\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 4s 185ms/step - loss: 1.0643 - accuracy: 0.7067\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 4s 183ms/step - loss: 0.7517 - accuracy: 0.8013\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 4s 181ms/step - loss: 0.5845 - accuracy: 0.8427\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 4s 179ms/step - loss: 0.4816 - accuracy: 0.8813\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 4s 180ms/step - loss: 0.4065 - accuracy: 0.9160\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 4s 179ms/step - loss: 0.3473 - accuracy: 0.9400\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 4s 179ms/step - loss: 0.2988 - accuracy: 0.9533\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 4s 179ms/step - loss: 0.2680 - accuracy: 0.9680\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 4s 177ms/step - loss: 0.2328 - accuracy: 0.9747\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff56a010050>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MobileNetmodel.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7W7HLI2_y3w",
        "outputId": "a078fdc2-4d93-438b-e1f7-a91ba3fcb2fa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 16s 189ms/step - loss: 0.5633 - accuracy: 0.8192\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5632665753364563, 0.8191999793052673]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(MobileNetmodel.predict(test_data),axis=1)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMizrSxAZzkC",
        "outputId": "7816fcb4-d7aa-4c8b-e2eb-4bcc4b2517ee"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 2, 8, ..., 8, 0, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6xdCIXLvbKeh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}